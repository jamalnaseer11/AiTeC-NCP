{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8789148,"sourceType":"datasetVersion","datasetId":5284049}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Convolutional Neural Network\n\n# Importing the libraries\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntf.__version__\n\n# Part 1 - Data Preprocessing\n\n# Preprocessing the Training set\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntraining_set = train_datagen.flow_from_directory('/kaggle/input/catsanddogs/dataset/training_set',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')\n\n# Preprocessing the Test set\ntest_datagen = ImageDataGenerator(rescale = 1./255)\ntest_set = test_datagen.flow_from_directory('/kaggle/input/catsanddogs/dataset/test_set',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')\n\n# Part 2 - Building the CNN\n\n# Initialising the CNN\ncnn = tf.keras.models.Sequential()\n\n# Step 1 - Convolution\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n\n# Step 2 - Pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\n# Adding a second convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\n# Step 3 - Flattening\ncnn.add(tf.keras.layers.Flatten())\n\n# Step 4 - Full Connection\ncnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n\n# Step 5 - Output Layer\ncnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n\n# Part 3 - Training the CNN\n\n# Compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Training the CNN on the Training set and evaluating it on the Test set\ncnn.fit(x = training_set, validation_data = test_set, epochs = 25)\n\n# Part 4 - Making a single prediction\n\nimport numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img('/kaggle/input/catsanddogs/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T04:31:49.378535Z","iopub.execute_input":"2024-06-26T04:31:49.379321Z","iopub.status.idle":"2024-06-26T04:44:26.989934Z","shell.execute_reply.started":"2024-06-26T04:31:49.379288Z","shell.execute_reply":"2024-06-26T04:44:26.989054Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-26 04:31:51.281371: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-26 04:31:51.281480: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-26 04:31:51.407178: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 8000 images belonging to 2 classes.\nFound 2000 images belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  3/250\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 90ms/step - accuracy: 0.6319 - loss: 0.7097","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1719376331.504677     120 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1719376331.522361     120 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m243/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 166ms/step - accuracy: 0.5540 - loss: 0.6932","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719376372.557450     121 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 196ms/step - accuracy: 0.5548 - loss: 0.6927 - val_accuracy: 0.6315 - val_loss: 0.6472\nEpoch 2/25\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719376380.375494     122 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - accuracy: 0.6272 - loss: 0.6497 - val_accuracy: 0.6715 - val_loss: 0.6276\nEpoch 3/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 115ms/step - accuracy: 0.6539 - loss: 0.6273 - val_accuracy: 0.6970 - val_loss: 0.6009\nEpoch 4/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.6974 - loss: 0.5744 - val_accuracy: 0.7185 - val_loss: 0.5557\nEpoch 5/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 114ms/step - accuracy: 0.7405 - loss: 0.5241 - val_accuracy: 0.7375 - val_loss: 0.5509\nEpoch 6/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - accuracy: 0.7542 - loss: 0.5065 - val_accuracy: 0.7425 - val_loss: 0.5233\nEpoch 7/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 114ms/step - accuracy: 0.7566 - loss: 0.4921 - val_accuracy: 0.7610 - val_loss: 0.4909\nEpoch 8/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.7972 - loss: 0.4461 - val_accuracy: 0.7740 - val_loss: 0.4953\nEpoch 9/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 112ms/step - accuracy: 0.7973 - loss: 0.4337 - val_accuracy: 0.7455 - val_loss: 0.5202\nEpoch 10/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.8005 - loss: 0.4175 - val_accuracy: 0.7630 - val_loss: 0.4990\nEpoch 11/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - accuracy: 0.8206 - loss: 0.3897 - val_accuracy: 0.7860 - val_loss: 0.4697\nEpoch 12/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - accuracy: 0.8215 - loss: 0.3832 - val_accuracy: 0.7345 - val_loss: 0.5819\nEpoch 13/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - accuracy: 0.8289 - loss: 0.3765 - val_accuracy: 0.7900 - val_loss: 0.4756\nEpoch 14/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 111ms/step - accuracy: 0.8392 - loss: 0.3543 - val_accuracy: 0.7865 - val_loss: 0.4750\nEpoch 15/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.8608 - loss: 0.3225 - val_accuracy: 0.7950 - val_loss: 0.4693\nEpoch 16/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 113ms/step - accuracy: 0.8564 - loss: 0.3201 - val_accuracy: 0.7960 - val_loss: 0.4655\nEpoch 17/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - accuracy: 0.8689 - loss: 0.3023 - val_accuracy: 0.7960 - val_loss: 0.5160\nEpoch 18/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 114ms/step - accuracy: 0.8795 - loss: 0.2822 - val_accuracy: 0.8010 - val_loss: 0.4863\nEpoch 19/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 110ms/step - accuracy: 0.8864 - loss: 0.2776 - val_accuracy: 0.7925 - val_loss: 0.4833\nEpoch 20/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 114ms/step - accuracy: 0.8945 - loss: 0.2558 - val_accuracy: 0.7905 - val_loss: 0.5165\nEpoch 21/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 109ms/step - accuracy: 0.8982 - loss: 0.2442 - val_accuracy: 0.7710 - val_loss: 0.5961\nEpoch 22/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 111ms/step - accuracy: 0.9006 - loss: 0.2429 - val_accuracy: 0.7900 - val_loss: 0.5635\nEpoch 23/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 108ms/step - accuracy: 0.9119 - loss: 0.2100 - val_accuracy: 0.8020 - val_loss: 0.5538\nEpoch 24/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 112ms/step - accuracy: 0.9159 - loss: 0.2060 - val_accuracy: 0.8010 - val_loss: 0.5536\nEpoch 25/25\n\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 112ms/step - accuracy: 0.9242 - loss: 0.1947 - val_accuracy: 0.7935 - val_loss: 0.6148\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595ms/step\ndog\n","output_type":"stream"}]}]}