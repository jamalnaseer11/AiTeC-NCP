{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8652083,"sourceType":"datasetVersion","datasetId":5182622}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#DATA PREPROCESSING    important(the data must be splitted into dependant and independent columns/data.....Then for training the data is split again for training sets and test sets) other sections are implemented sometimes depending on #the dataset\n\n\n\n\n#IMPORT IMPROTANT LIBRARIES\n\nimport numpy as np         #numpy is used for most of the mathematical (as np ables us to use it as a shortcut)\nimport matplotlib.pyplot as plt     # for charts and graphs\nimport pandas as pd\n\n\n\n\n#IMPORTING THE DATASET\n#1. ALWAYS REMEMBER TO CHANGE THE DIRECTORY OR PROVIDE THE FULL PATH\n\n\ndataset = pd.read_csv('/kaggle/input/data-csv/Data.csv')       #stores all the data and columns into the array dataset\nX= dataset.iloc[:, :-1].values        # stores all the values of the columns except the last one (because last one is dependant )\ny= dataset.iloc[:, 3].values            # stores all the values of the last one in y (dependant)\n\nprint('Independent Variables',X)\nprint('Dependent Variables',y)\n\n\n\n#TAKING CARE OF MISSING DATA\n#some times there is missing data in the dataset which can be filled using the following/ there are different strategies used but the most common is mean strategy which takes the mean of the other values in the column or sometimes even #row and places the mean there\n\nfrom sklearn.impute import SimpleImputer                              # library import\nimputer= SimpleImputer(missing_values=np.nan, strategy = 'mean')              # setting all missing values as 'NAN' then setting the strategy as mean and storing object\nimputer = imputer.fit(X[: , 1:3])\nX[: , 1:3] = imputer.transform(X[:, 1:3])     \n\nprint('Independent variable after taking care of missing values',X)\n\n\n\n#ENCODING CATEGORICAL DATA\n# when there is data that can be categorized for example country names or a Boolean of yes or no, labeling can be done to give them unique numbers\n# further onehotencoder can be used to give only values so that the categories cannot be valued\n\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder \nlabelencoder_X= LabelEncoder()      #Labelencoder does simple encoding which gives values to the categories which is sometime not needed    // Onehotencoder      labelencoder_X = LabelEncoder()                                       #makes separate columns       \nX[:, 0]= labelencoder_X.fit_transform(X[:, 0])                         # fits label encoding into first columns and then transforms it\n\nfirst_column = X[:, 0].reshape(-1, 1)\nonehotencoder =OneHotEncoder()    \n# inside brackets specifies that first column needs to be labeled\nefc= onehotencoder.fit_transform(first_column).toarray()\nX = np.hstack((efc, X[:, 1:]))\n\nprint('After Encoding',X)\n\n\n#SPLITTING DATASET INTO TRAINING AND TEST SET\n# the train set is the dataset that the machine learns corelations etc on and then the predicted data in tested and compared with test dataset\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test , y_train , y_test = train_test_split(X, y , test_size= 0.2, random_state=0)     \nprint('Test sets',X_test,y_test)\nprint('Train sets',X_train,y_train)\n\n\n# Feature Scaling\n#this is rarely used because most of the libraires have built-in function of scaling\n# it normalizes or standardizes the values that are too much out range mostly the new range of all values is -1 to 1\n\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.fit_transform(X_test)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T05:01:45.206260Z","iopub.execute_input":"2024-06-10T05:01:45.206775Z","iopub.status.idle":"2024-06-10T05:01:45.237579Z","shell.execute_reply.started":"2024-06-10T05:01:45.206721Z","shell.execute_reply":"2024-06-10T05:01:45.236326Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Independent Variables [['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 nan]\n ['France' 35.0 58000.0]\n ['Spain' nan 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\nDependent Variables ['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\nIndependent variable after taking care of missing values [['France' 44.0 72000.0]\n ['Spain' 27.0 48000.0]\n ['Germany' 30.0 54000.0]\n ['Spain' 38.0 61000.0]\n ['Germany' 40.0 63777.77777777778]\n ['France' 35.0 58000.0]\n ['Spain' 38.77777777777778 52000.0]\n ['France' 48.0 79000.0]\n ['Germany' 50.0 83000.0]\n ['France' 37.0 67000.0]]\nAfter Encoding [[1.0 0.0 0.0 44.0 72000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 1.0 0.0 30.0 54000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 35.0 58000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 1.0 0.0 50.0 83000.0]\n [1.0 0.0 0.0 37.0 67000.0]]\nTest sets [[0.0 1.0 0.0 30.0 54000.0]\n [0.0 1.0 0.0 50.0 83000.0]] ['No' 'No']\nTrain sets [[0.0 1.0 0.0 40.0 63777.77777777778]\n [1.0 0.0 0.0 37.0 67000.0]\n [0.0 0.0 1.0 27.0 48000.0]\n [0.0 0.0 1.0 38.77777777777778 52000.0]\n [1.0 0.0 0.0 48.0 79000.0]\n [0.0 0.0 1.0 38.0 61000.0]\n [1.0 0.0 0.0 44.0 72000.0]\n [1.0 0.0 0.0 35.0 58000.0]] ['Yes' 'Yes' 'Yes' 'No' 'Yes' 'No' 'No' 'Yes']\n","output_type":"stream"}]}]}